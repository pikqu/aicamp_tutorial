{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RunDown of our workshop\n",
    "\n",
    "* Quick introduction to essential parts of tensorflow\n",
    "* Neural network essentials\n",
    "* Neural network training code\n",
    "* Transfer learning\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow essentials\n",
    "Tensorflow is low level library, but there exists high level interfaces that help us to do faster prototyping of ideas. If you want you can check them on your own\n",
    "* TF Learn (tf.contrib.learn): simplified interface that helps users transition from the the world of one-liner such as scikit-learn\n",
    "* TF Slim (tf.contrib.slim): lightweight library for defining, training and evaluating complex models in TensorFlow.\n",
    "* High level API: Keras, TFLearn, Pretty Tensor\n",
    "\n",
    "In this tutorial we will be using native tensorflow and slim. In future Keras will be fully integrated to tensorflow as parts of slim has been integrated from contrib to core."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensors\n",
    "\n",
    "The central unit of data in TensorFlow is the tensor. A tensor consists of a set of primitive values shaped into an array of any number of dimensions. A tensor's rank is its number of dimensions. Here are some examples of tensors:\n",
    "\n",
    "```python\n",
    "3 # a rank 0 tensor; this is a scalar with shape []\n",
    "[1. ,2., 3.] # a rank 1 tensor; this is a vector with shape [3]\n",
    "[[1., 2., 3.], [4., 5., 6.]] # a rank 2 tensor; a matrix with shape [2, 3]\n",
    "[[[1., 2., 3.]], [[7., 8., 9.]]] # a rank 3 tensor with shape [2, 1, 3]\n",
    "```\n",
    "You can look at tensors as an n-dimensional matrix\n",
    "* 0-d tensor: scalar (number)\n",
    "* 1-d tensor: vector\n",
    "* 2-d tensor: matrix\n",
    "* and so on \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4 5 6] (3,)\n",
      "[[1 3 6]\n",
      " [4 4 5]] (2, 3)\n",
      "[[[2 1 3]]\n",
      "\n",
      " [[1 9 4]]] (2, 1, 3)\n",
      "<function divide at 0x7fd5b437eaa0>\n",
      "<ufunc 'divide'>\n"
     ]
    }
   ],
   "source": [
    "#As you see interface is very similar to numpy.\n",
    "a = np.random.randint(1, 10, size=3)\n",
    "print a, a.shape\n",
    "a = np.random.randint(1, 10, size=(2,3))\n",
    "print a, a.shape\n",
    "a = np.random.randint(1, 10, size=(2,1,3))\n",
    "print a, a.shape\n",
    "#Tensorflow computation primitives mimic numpy funtions\n",
    "print tf.divide\n",
    "print np.divide"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Computational Graph\n",
    "\n",
    "You might think of TensorFlow Core programs as consisting of two discrete sections:\n",
    "\n",
    "1. Building the computational graph.\n",
    "2. Running the computational graph.\n",
    "\n",
    "A computational graph is a series of TensorFlow operations arranged into a graph of nodes. Let's build a simple computational graph. When not stated explicitly with tf.Graph() - all defined operations is stored in default graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Add_2:0\", shape=(), dtype=int32)\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "a = tf.add(2,3)\n",
    "print a\n",
    "b = np.add(2,3)\n",
    "print b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Session  \n",
    "tf.Session() -  A Session object encapsulates the environment in which **Operation objects** (add) are\n",
    "executed, and **Tensor objects**(2 and 3) are evaluated.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7776\n",
      "[7776, 10]\n"
     ]
    }
   ],
   "source": [
    "x = 2\n",
    "y = 3\n",
    "op1 = tf.add(x, y)\n",
    "op2 = tf.multiply(x, y)\n",
    "\n",
    "#What is value of useless? Why?\n",
    "useless = tf.multiply(x, op1)\n",
    "op3 = tf.pow(op2, op1)\n",
    "gpu_opts = tf.GPUOptions(per_process_gpu_memory_fraction=0.05)\n",
    "with tf.Session(config=tf.ConfigProto(gpu_options=gpu_opts)) as sess:\n",
    "    print sess.run(op3)\n",
    "    \n",
    "#     We can evalue different subgraphs simultaneously\n",
    "#     print sess.run([op3, useless])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constants and variables\n",
    "Lets explore tensor objecs which are **constants** and **variables**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"a_9:0\", shape=(), dtype=int32)\n",
      "Tensor(\"b_3:0\", shape=(2,), dtype=int32)\n",
      "Tensor(\"c_2:0\", shape=(10,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "a = tf.constant(2, name=\"a\")\n",
    "print a\n",
    "b = tf.constant([2,2], name=\"b\")\n",
    "print b\n",
    "c = tf.constant(np.random.randint(1,10, 10), name=\"c\")\n",
    "print c\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "tf.linspace(10.0, 13.0, 4) ==> [10.0 11.0 12.0 13.0]\n",
    "tf.range(start, limit, delta) ==> [3, 6, 9, 12, 15]\n",
    "```\n",
    "But you cant do for _ in tf.range(10) as tensor object are not iterable\n",
    "```python\n",
    "tf.random_uniform((3,3))\n",
    "tf.random_normal((5,5))\n",
    "tf.int32 == np.int32 # True\n",
    "```\n",
    "As you see interface is very similar to numpy or python\n",
    "\n",
    "```python\n",
    "# create variable a with scalar value\n",
    "a = tf.Variable(2, name=\"scalar\")\n",
    "# create variable b as a vector\n",
    "b = tf.Variable([2, 3], name=\"vector\")\n",
    "# create variable c as a 2x2 matrix\n",
    "c = tf.Variable([[0, 1], [2, 3]], name=\"matrix\")\n",
    "# create variable W as 784 x 10 tensor, filled with zeros\n",
    "W = tf.Variable(tf.zeros([784,10]))\n",
    "```\n",
    "\n",
    "\n",
    "**You always have to initialize your variables!!!**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"vector_4/read:0\", shape=(2,), dtype=int32)\n",
      "[2 3]\n"
     ]
    }
   ],
   "source": [
    "b = tf.Variable([2, 3], name=\"vector\")\n",
    "print b\n",
    "# b.eval() # try it \n",
    "\n",
    "init_op  = tf.global_variables_initializer()\n",
    "gpu_opts = tf.GPUOptions(per_process_gpu_memory_fraction=0.05)\n",
    "with tf.Session(config=tf.ConfigProto(gpu_options=gpu_opts)) as sess:\n",
    "    sess.run(init_op)\n",
    "    #you can evaluate using sess.run(b) or b.eval() if you have active session\n",
    "    print b.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code challenge\n",
    "* What value print function will print and why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "W = tf.Variable(10)\n",
    "W.assign(100)\n",
    "gpu_opts = tf.GPUOptions(per_process_gpu_memory_fraction=0.05)\n",
    "with tf.Session(config=tf.ConfigProto(gpu_options=gpu_opts)) as sess:\n",
    "    sess.run(W.initializer)\n",
    "    #print W.eval() # >> What value do you get and why?\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Placeholders\n",
    "Imagine you want to calculate function y = x*2 + b, but you want to suply x values on runtime. \n",
    "\n",
    "Placeholders let you inject data directly to computation grahp. Feed values to placeholder directly using dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 9.]\n",
      "[  9.  11.]\n"
     ]
    }
   ],
   "source": [
    "# create a placeholder of type float 32-bit, shape is a vector of any number of elements\n",
    "x = tf.placeholder(tf.float32, shape=None)\n",
    "# create a constant of type float 32-bit, shape is a vector of 1 elements\n",
    "b = tf.constant(5, tf.float32)\n",
    "# use the placeholder as you would a constant or a variable\n",
    "y = 2*x + b # \n",
    "gpu_opts = tf.GPUOptions(per_process_gpu_memory_fraction=0.05)\n",
    "with tf.Session(config=tf.ConfigProto(gpu_options=gpu_opts)) as sess:\n",
    "# feed [1, 2, 3] to placeholder a via the dict {a: [1, 2, 3]}\n",
    "# fetch value of \n",
    "    print sess.run(y, {x: [2]})\n",
    "    print sess.run(y, {x: [2,3]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The trap of lazy loading*\n",
    "Defer creating/initializing an object until it is needed. The non bug that i personaly commited:). Lets examine some code\n",
    "\n",
    "* The good\n",
    "\n",
    "```python\n",
    "    x = tf.Variable(10, name='x')\n",
    "    y = tf.Variable(20, name='y')\n",
    "    z = tf.add(x, y) # you create the node for add node before executing the graph\n",
    "    gpu_opts = tf.GPUOptions(per_process_gpu_memory_fraction=0.05)\n",
    "    with tf.Session(config=tf.ConfigProto(gpu_options=gpu_opts)) as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        for _ in range(10):\n",
    "            sess.run(z)\n",
    "```\n",
    "\n",
    "* The bad\n",
    "\n",
    "```python\n",
    "    x = tf.Variable(10, name='x')\n",
    "    y = tf.Variable(20, name='y')\n",
    "    gpu_opts = tf.GPUOptions(per_process_gpu_memory_fraction=0.05)\n",
    "    with tf.Session(config=tf.ConfigProto(gpu_options=gpu_opts)) as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        for _ in range(10):\n",
    "            sess.run(tf.add(x,y))\n",
    "```\n",
    "\n",
    "1. and no ugly, but what is the source of the problem?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lets build first model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
