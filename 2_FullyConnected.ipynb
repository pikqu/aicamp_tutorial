{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import time\n",
    "import os\n",
    "from os.path import exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's get our hands dirty\n",
    "We going to build classification model that is capable of handwritten digits recognition. We gona use MNIST data set. Lets explore it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "train db: (55000, 784), validation: (5000, 784)  test: (10000, 784)\n",
      "train db labels (55000, 10)\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets('MNIST_data/', one_hot=True)\n",
    "\n",
    "train_img = mnist.train.images\n",
    "print \"train db: {}, validation: {}  test: {}\".format(train_img.shape, mnist.validation.images.shape, \n",
    "                                                      mnist.test.images.shape)\n",
    "print \"train db labels {}\".format(mnist.train.labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAa4AAAGCCAYAAAC4myfXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAAPYQAAD2EBqD+naQAAIABJREFUeJzt3Xm8ldMex/HPUSnzUCpCUcZucinDTQqRhJu4IlOmCBcZ\nuoZEpTI2GxK5udeQSCRdCqV0uRIh85h5zJAi5dw/vH7rWc/Z+5z2Pntc+3zf//S81rPP3us87X3W\n/q3nt36rrLy8HBERkVCsVegOiIiIpEMDl4iIBEUDl4iIBEUDl4iIBEUDl4iIBEUDl4iIBEUDl4iI\nBEUDl4iIBEUDl4iIBEUDl4iIBEUDl4iIBEUDl4iIBEUDl4iIBEUDl4iIBKV2IV+8rKxMe6p4ysvL\ny9J5vK5fXLrXD3QNfbp+mdNnODOpXj9FXCIiEhQNXCIiEhQNXCIiEhQNXCIiEhQNXCIiEpSCZhWK\niGTTWmtF38VvvPFGAM455xzXtvfeewOwYMGC/HZMskoRl4iIBEUDl4iIBEVThSISvIYNGwIwePBg\n19a7d++Ex22zzTaApgorGj9+PADHHXeca9tnn30AWLhwYUH6VBVFXCIiEhRFXFJtTZs2BeC0004D\n4PLLL3fnysv/qGRTVhZVcHnjjTcA6N+/v2t76KGHct5PKV2bb745AP369QOSR1lz5851x88//3x+\nOhaYDz/8EIB69eq5tu222w5QxCUiIpIxDVwiIhIUTRVKSjbbbDMALr30UtdmN3Lr168PRNODFY/N\nDjvsAMDw4cNdm03jfPPNN1nucXFYe+21AXjyySddW7t27YBoGvX7779353bZZRcAPv7443x1MTi1\na0d/ti677DIgvlbLjB07FoALL7zQta1cuTLHvQvTkiVLEtpOPPFEACZNmpTv7qyRIi4REQlKjYm4\nTj75ZCAeCXz77bcA7LTTTgDMnz/fnZs3b14ee1ec/GQLSzP2r59FDNbmRwlff/11wvM1aNAAgGbN\nmrm2OXPmANCyZcss9bo4WKR1xx13AFGU5Zs6dSoA11xzjWv77LPP0nqdRo0aAfDll19Wq58hGjZs\nmDuuGGmNGzfOHf/973/PW59K0W+//VboLlRKEZeIiASlaCOuY4891h3vtttuQBQ1VcfGG2+c0LZ6\n9Wog+na8YsUKd2758uUAvPrqq67t6KOPBpJHE6WoW7du7tiiqmT3rl5//XUA9ttvP9eW7J6VLWi0\nKAui+16lxu6r+As6zU033QTAxRdfDMAvv/yS1nPfcMMN7tg+E/7C25EjR6bX2UAMHDgQiN+zMnY/\n64ILLshrn0rFEUcckdB27733FqAnqVHEJSIiQdHAJSIiQSlLNvWTtxcvK0t4cduK4LzzznNttWrV\nyl+nqvD0008D8WnMbN4ULy8vL1vzoyLJrl827LjjjgC88MILrs0SWfxpUpsO7Nu3LwDnn3++Ozd0\n6FAgeZqt/577/fffAejTpw8At912W7X7ne71g+xeQz/B5H//+x8A66yzDgDLli1z5zbddFMAVq1a\nldbzt2nTBoD//Oc/Cc/lT5FVd6qw0Ncvmb322ssdT58+HYh+Z4iSMc466ywgej8VSrF8hlO16667\nAlFFkR9//NGd23rrrYH4LZRcS/X6KeISEZGgFF1yhiVA+FHWK6+8AqQ+8lsqu6Ubp+rAAw90x7b4\nzk/dtuQD/6Zljx49gNJK2HjzzTcBaNu2rWuz6CpZ0oXVhzv99NNdm0VOfsRlN4D9b8UWfU2ZMiUr\nfS+kSy65xB1bpGVR1eGHH+7OpRtpGUvm8CMOS1lO970eikGDBrlj+72nTZvm2iwppdCRVqjq1q0L\nQJ06dYD4dcxnpJUuRVwiIhIUDVwiIhKUopsqPOCAA4D4je5Zs2YB8NNPP+X0tf1qGRMnTgTg0Ucf\ndW1WYcNfr2RTipZUUkpsynBNbJr0rbfecm2WzGGJGxBNpflbnVQ1BRma3XffPaHNEilmz56dcM6m\nw20dYWWaN28OQIcOHRLOPfDAA0C0LUWpadWqVUKbbXoI8Omnn+azOyXnyCOPLHQXqkURl4iIBKXo\nIq6333479m+hvP/++wAMGDDAtU2ePDnhcRZFlGLE5dt3332BKFUeokjLNoj0q2BYeq1VlYcoEcNP\nZOnSpUuOelwc7Oa3b4899gDg6quvBqBTp05pPae/BMOWHZSarl27AtC4cWPX9uCDDwLxWRDJjG3E\nGRpFXCIiEhQNXCIiEpSimyqU4tSzZ08gvlar4rYmftKFTREmS8QYPXq0a1u4cGGOepx/1113nTue\nMGECECXyPPXUU+6cTbuutVb1vjf6yQmLFy+u1nMUu+7duye02VRhNqr9+Ndea8DCo4hLRESCooir\nElY7z68ekUy9evWAKBX6xRdfzG3HCizZt92q2ubOnevarJ5eKUVZPqvt5rNt5jt27JhwzhJYHnro\nIdfWpEkToOpNEBcsWJBJN4NQv379hDZbYpEuv96hfa7tOkNUree7776r1vOHxl9+4VcGgtSXwBSa\nIi4REQlKjYm4LO3z+OOPd21+NfPKHu/fo0lm/fXXB6J7GBtttFFG/SxW99xzDwBNmzZ1bQ0aNACi\nFPn11lsv4ef85QSlGmkZu68FsHLlykofd9999wHw8ccfA9GGpgCXXnpppT/37LPPAvDYY49l1M9i\ntckmm7hjK0SQLv89aLMf22yzjWtLtth7+PDhAPTq1atarxka/xq1a9cuds6KPRQ7RVwiIhIUDVwi\nIhKUkpwqtEoEfu0423pj2223zclr+tNEpeiZZ56J/euzqUKrBAHQrVs3IF5RxKpklEJdwmQ++eQT\nd3zNNddU6zl+/vnnSs/ZMoLqbotS7CyRBaIp+FTZ5q629QvEK7lUpVSn9ytTVbWMGTNm5LEn1aeI\nS0REghJ8xNWiRQsAbr31Vte2//77A2tOrPjoo48AWLp0acK5/v37A/Drr7+6trFjxwLJv8l99tln\n6XS74GyBcDY2wLQU2qOOOsq12Te3zp07uzZLjKnu1vI1gZ+oYWyB7DvvvJPv7uTV8uXL3bHtNJDs\ns7bhhhu6Y9vI1TYuzfR1a4IrrrgioW369OkAvPTSS/nuTrUo4hIRkaBo4BIRkaAEO1VoGxSeffbZ\nQLTZHsCyZcsA+P77712bTU/5U3rz588HoinDNfnhhx8S2mxzy2nTpqXc90KxGnkQJU3YNN8JJ5yQ\n1dcaMmQIAAcddJBrS/VmeU12xhlnJLTNnDkTgJdffjnf3ckrPzHF3pf+e2bw4MFAfKscf41WOvwp\nMX+z05og2Ro5u12SbKq6GCniEhGRoAQbce29995AFGk98sgj7pxFE8lSt9O16667umO/aoSx5I1i\nrvFl31D9BJavvvoKyG6k5a/IHzduHLDmBBmJp2P7iQemJiaz2Pvn0EMPdW22AWe6/Orvt99+OxBP\nULDPQqlr1KgRAHXq1HFtoX4+FXGJiEhQNHCJiEhQgp0qPPPMMwF45ZVXgHjVhmyydWIQhdq+EIpS\nHnHEEUD8RvecOXOy9vxWOcM2+vNfy9/ypJinUwvJnwKzrVF+++0311bd7TxCZusA/XWGjRs3XuPP\n+e+3e++9N/YvwKOPPpqtLgbH1rr5U9N2vayIdigUcYmISFCCjbhs07dcRVrG34TO+Gn2o0aNyunr\nZ4MlqfjblVtqvFWzeOONN9y5ZJthWmJK+/btXZtFclaX0L/Ra9/k/OsTwrUqhDFjxiS02TILqBkb\nR6bDrwu6aNEiAO644w4gnoixYsWK/HasCG255ZbueLfddks4/+STTwLw+OOP561P2aCIS0REghJs\nxJVrr776KhDdv/E98cQT7vi5557LW5+qy+4t+fegLEqaOHEiEL83kKxemd178bdUtwjL/1ljC5Ct\norlUrm7dugltdu9WIueeey4AN998s2sLZcFsoTRs2NAdN2nSJOF8ss9/CBRxiYhIUDRwiYhIUDRV\nWIlmzZoB8c3trFbhiBEjCtGljPXp08cdW7JFmzZtgPhNbduA058+SDYtaNtB2FTk0KFD3bmHHnoo\nq32vaTQF9oeqNj2U6pk3b5479isOhUQRl4iIBEURl8e2/wZYZ511gHhacu/evYEwEjKS8RdzdunS\nBYgqbvvs95wyZYpr++abbxIeZ+ntWlicfX4l/wEDBgAwaNCgQnVHArVw4UJ37C+HCV3p/CYiIlIj\naOASEZGgaKqQqMx/v379XJvVinvggQdc2/3335/fjuWQTf35CRsmWZvkjr/Wzbbb2HjjjV2bnzgj\nIoq4REQkMGWFXDFdVlZWFMu1LeXd38Lbtkm3bdPzoby8PK1d3Yrl+hWLdK8f6Br6dP0yp89wZlK9\nfoq4REQkKBq4REQkKJoqLCKaZsiMproyo+uXOX2GM6OpQhERKUkFjbhERETSpYhLRESCooFLRESC\nooFLRESCooFLRESCooFLRESCooFLRESCooFLRESCooFLRESCooFLRESCooFLRESCooFLRESCooFL\nRESCooFLRESCooFLRESCooFLRESCooFLRESCooFLRESCooFLRESCooFLRESCooFLRESCooFLRESC\nooFLRESCooFLRESCooFLRESCUruQL15WVlZeyNcvNuXl5WXpPF7XLy7d6we6hj5dv8zpM5yZVK+f\nIi4REQmKBi4REQmKBi4REQmKBi4REQmKBi4REQmKBi4REQmKBi4REQmKBi4REQlKQRcgS2kZMGCA\nO+7RowcAhx12mGt7//33896nYrbzzjsDcP7557u2008/HYBx48a5tjPPPDO/HZOS1rBhQ3fcunVr\nAA4//HAAOnTo4M61bNkSgDvvvNO1vffeewAMHz7ctf3666+x5990003d8XfffZetbsco4hIRkaAo\n4vK0a9fOHdu33OOOO67Kn5k3bx4AU6ZMAeCuu+5y53L1baPY1K9fH4iiBYAmTZoAsNtuu7k2RVx/\nOOmkkwAYPHgwEF0rgN9//x2AQw45pNKfP/74493xww8/DMBPP/2U9X5KaTnttNMAuPTSS11b06ZN\nY48pK4sqLpWX/1GNqlevXgnP9csvv7jjESNGxM7de++97rhz587V73AVFHGJiEhQNHCJiEhQavRU\nYe3af/z6V155JQDnnHOOO7fhhhsCUbhcmX322QeIphl33XVXdy5ZiF2KTjzxRCA+5SV/qFOnDhCf\nMrntttuA6P2Xqj59+gAwevRo1/bBBx8AcMUVV7i2SZMmVa+zgWjevLk7tsSWv/zlL0CU8ALRdP/E\niRPz2Lvi4k8F2hRhxelBgBUrVgDw888/uzb729egQQPXZlOJ119/vWv7/vvvgSiJY4sttshK36ui\niEtERIJSoyOuIUOGAHDRRRcByW9MJjN37lx3vO+++8bOHXjgge54gw02AEr/xvl+++1X6C4UrQsu\nuACAoUOHpvT4N998E4hHVca++a61VvR906KPW265JeHxpRB5WcQK0RKLf/7zn67tt99+A6LP8scf\nf+zOnXHGGUDNjrjsbxtEkZZdM4DJkycDUXr7yy+/nPAcRx99tDv+xz/+AURp9AD16tWLPf6zzz7L\ntNtrpIhLRESCUmMiLrufYN/MIPo2bPz5XUvxtDR3iL7N/fjjj65twoQJAPTs2ROAb7/91p1btWpV\nVvperOz+nt1fkIhFCrvssssaH/vJJ5+44969ewPw7LPPpvV6G220kTu2xctt2rQB4OKLL07ruYrB\n2muvDURLBiD6PRYvXuza7DM8c+ZMALbcckt3zo7tfQpRGveCBQty0e2ic+yxxya02RIeiO5PV+X+\n++93x1999RUAs2bNqvTxU6dOTaeL1aKIS0REgqKBS0REglJjpgqtAoZ/s9K8/fbbAPztb39zba+9\n9lpKz1uxTte7777rji3FtFRZTTK/NllNVqtWLXds77Njjjmm0sdbks+RRx7p2vyp5oqmT58OwDbb\nbOPaTjjhBCCesGFJQf6UWgjq1q3rjm+//XYgXrnGPpP+MpOFCxfGnsOfdrWkKP+zbMkvfhJVKfM/\nm5Zwlsn74p133gHgyy+/dG0Vn89/L+aKIi4REQlKjYm4LrnkEiCe8r5o0SIADj74YCD+LSKZdddd\nF4jScgHat28PRN+Uu3fvnqUeh82upf8NuNS1bdvWHV999dWVPm7+/PlAVDk/1eUSFl2ccsoprs2W\nY/hRWGgs0ho4cKBrs0jr1VdfdW22iPuLL75I6XltBsVfGL9y5UoA1ltvPdfmJ2WVGj9RwirA+3+/\n/J0JKmNJPgDXXXcdEEX1AJdffjkAzzzzDBDV28wlRVwiIhIUDVwiIhKUGjNVaDcm/YoYNn2YbIrQ\nbjD6tQf/9a9/AbDjjju6Npt6tBvnNUnfvn0rPffKK68A8Nxzz+WrOwVjCRI2ZZKMTQ8CdOrUCUhM\n7KmpbMq0X79+rs3WTNo0PqQ+RWg23njjhDarq1fK04M+fypwu+22A+J/v4YNGwZE61b9SkCXXXYZ\nAC1atHBtdrvEZ5VzbD1nssdkmyIuEREJSo2JuJKpKhnDIq0XXnihyud4/PHHgeQr1EudX4m7onys\nni8kv0K51SFMVhXbUt4tqoDMIy3/G/D666+fcN4quxT7xp22Aand8PejIKvs/vnnn6f1nJtvvrk7\nPuqoozLtYvCWLFnijgcNGgTEN3q0aiT2b6r1Wv2/i/Y30FLlrXILwI033ljtvldFEZeIiARFA5eI\niASlxkwV/vDDDwltNo1jpfz9qhfJphlsDciYMWNc24ABA4CoeKf8odSTVR588EF3XNXGeTYtk82t\nbWwaDWCzzTZLOG9r52xdTbGywsDNmjUD4KWXXnLnZsyYkdJzWLUSq6ZhmyUCbLvttlnoZdj8ZIuK\nRcVT5b+PbLPd9957z7UVIslIEZeIiASlxkRcp556KhBfiW9pm5bG2a5dO3cu2Y3Jc889F4Dx48fn\nrJ/FzlK/Ib6VBsRvrq9evTpvfcon21TPTyk2y5cvd8f//e9/gexGno0bNwaiDRIrk25CQ7HYeuut\n3bFVvfCvqfnrX//qju3/Y8MNNwTgo48+cucs6cNPs083pT5U3bp1A6KEDICWLVuu8ef8OoMWXd10\n001Z7l3mFHGJiEhQSjri8iMo2+jRT/esKNm5hx9+2B3X5EjLFnNa5ArRZn/GFjECfPrpp/npWJ7Z\n/Rh/S3njR/MHHXRQ1l/79NNPB5Iv8PTvM1x77bVZf+1c+OCDD4AoKrD7xQCTJk1K6Tnsft4VV1wB\nwK233urObbXVVkA84vIXgpeahg0buuNRo0YB8Y01bRbJf69MmzYNiOpAWuQKyaPdYqGIS0REgqKB\nS0REglIyU4V+6uuECROAeCposlqFxlaBz54927XZtgr777+/a7PN52bOnJmlXofDpgr9a2psmYCf\nIlsTPfLIIzl5XpvC9jeqrOj55593x08++WRO+pFt9lm86qqrAHj99dfdOT8Bw1hixeTJk11bVbUw\nrXKILXeBaNPOIUOGVLPXxcemRP3f0xKnli1b5tpsqx37+wjRdkyWgOEvtbBtUCZOnOjaUtmy5Oab\nb07vF6gGRVwiIhKU4CMuS5u96667XFvFpAGf/83UUpVvueUWAL777jt37v777wfiNblGjhwJpJZW\nWmrq1atX6bmlS5cC8W9mNdG8efNy8ryHHHIIECUgJPPUU0/l5LXzyT5zFY+ryzY7tJqIAN98803G\nz1ts+vfvD8SXp3z22WdAtIQHqq4fevbZZwPxmSurr+nXYb377rvX2B/7e5pLirhERCQoGrhERCQo\nwU4V2roDmyL0pwdtszh/XY1tmPb000+7NksqSMZudA4ePNi12cZqe+yxh2v73//+V71fIDCjR4+u\n9Jxta1DT+e8V21wvXQ0aNADi6+UGDhxY6eMtAcE2OZWI1XG05AWAhx56qFDdyZlkiSw2vffss8+m\n9Vz+ulVLRvM3SE1lqjAfFHGJiEhQgo24WrduDUSRll+jzKoW+NXe02XPu+eee7o2S0euXTvYy5YW\nv/L4JptsknDeEgKspllN529i2KRJE6DqCiJWm8+WXgD06dMn9vNrYt+sP/zww7T6WhN06NAhoe3r\nr78uQE9yy5ZL+JV/LGEqXX5STN++fYF4RQ6rrGGblRaKIi4REQmKBi4REQlK8HNeFh77G/tVd4rQ\nLzD5wAMPANCpU6cMehc2P8Fg9913B+LTEStWrABg1apVQHwK1dpKjSVB2HYaAH/+858B2G677Vyb\nTaP6awMrsvVFzZs3T+m1lyxZAsB9993n2l577bWUfrYm8tdvlTL7e+f/vrZp5DXXXJPwuKr42xFZ\n8ppVzYHoNoz9fUzGEucgd4lbirhERCQowUZcixYtAqIS/ckSBPx6ZJYi77NvKDvssAMA99xzjztn\nKbR+bUOrpeZvMV7T+Neja9euQLT9gdVCg/gWFaXENmn031v2vvGXZLRo0SKj1/Ej1jfeeAOAHj16\nAPDWW29l9NxSWqxGpp9I1qtXLyA+M2DLg5544olKn8uvtGGVOKyeIUTboFTlhhtucMeKuERERAg4\n4rKR/OKLLwaijdMgmt89+eSTXdvcuXMTnuPggw8Gom/K/v0biyz82oa2kZ/d2yl1/v0ZS3/17wMa\niw5KdfPIZPyFrAsWLABg5513dm3+fYF0WFTvb7nuV0OX9Pmfa78oQakYN24cAOeff75rs6Us6623\nnmuziMyPzCpK9jfQNuuE+CaUlfHru+aKIi4REQmKBi4REQlKsFOFxm5cv/nmm67Npmn8Sga2KVpV\n/OewG+7XXXeda6uqtmEpmjVrlju25Be/Jp7Vc7SbscVSxyzf2rdvD8AWW2zh2nr27AlA9+7dgfj0\njNW89FOPjU0L+pVgJDN+QtHbb79dwJ7khiWetW3b1rXZbY1u3bq5tlS2Y3rmmWfcsdUtTPdzfcop\np6T1+OpQxCUiIkEpS7aVfd5evKwsJy/eqFEjIJ6ebfwFxV9++SUAU6ZMAeLRVSGUl5eXrflRkVxd\nv1Cle/1A19BXatfvoosuAuD66693bTvttBMQn13JJn2GM5Pq9VPEJSIiQdHAJSIiQQk+OSMZmwK0\nG5QiUnP5W3AsW7asgD2RbFHEJSIiQSnJ5IxQ6cZuZkotuSDfdP0yp89wZpScISIiJUkDl4iIBEUD\nl4iIBEUDl4iIBKWgyRkiIiLpUsQlIiJB0cAlIiJB0cAlIiJB0cAlIiJB0cAlIiJB0cAlIiJB0cAl\nIiJB0cAlIiJB0cAlIiJB0cAlIiJB0cAlIiJB0cAlIiJB0cAlIiJB0cAlIiJB0cAlIiJB0cAlIiJB\n0cAlIiJB0cAlIiJB0cAlIiJB0cAlIiJB0cAlIiJB0cAlIiJB0cAlIiJBqV3IFy8rKysv5OsXm/Ly\n8rJ0Hq/rF5fu9QNdQ5+uX+b0Gc5MqtdPEZeIiARFA5eIiARFA5eIiARFA5eIiARFA5eIiARFA5eI\niARFA5eIiARFA5eIiASloAuQpbi1adPGHe+0004ANGrUyLXtsMMOAOy7774AbL/99u7cJ598AsCg\nQYNc2/jx43PX2QCNGTMGgLPOOsu1HXDAAQDMnj27EF0SCYIiLhERCUpJR1xlZVH1kGOOOQaAK6+8\n0rVZxFCVt956yx3bt+Evv/zSta1atSrjfhabrl27AjB16lTXVqtWLQDKyxMr1Nh1/v33313bFlts\nAcDYsWNdW+3af7zdbrnlliz3OEx2Lf1reuCBBwKKuBo3bgxAly5dXJtF/fYvwCGHHALA8OHDAXjs\nscfcuTfeeAOAFStWuLYffvgBiN7PACeeeCIA6667LgC33XabO/fbb79l+qtIDijiEhGRoGjgEhGR\noJTkVOFaa/0xHp999tmubdSoUQmPW716NQDLly8H4tMH66yzDhBPOPj4448BWLx4sWvr1KkTEJ8+\nDN1RRx0FRNcRoumsZcuWubYXXngh9nOvvvqqO15//fUBOO6441zbscceC8Dtt9/u2jQVE9eqVSsA\n6tSp49pqyjU66aST3PGECROA5FPTPjt/wQUXANC3b9+Ex3zwwQfu+IQTTgCihCKAoUOHxh4/Z84c\nd/zaa6+l1HfJL0VcIiISlJKMuE477TSg6igL4KqrrgJgyJAhAGy99dbu3MUXXwzAmWee6dosImvZ\nsqVrmzVrFgDt2rUD4Mcff8y4/4X297//HYDmzZu7Noso/W+0lvJelaVLl7rjCy+8EIj+f0CJGhVZ\nYky9evVcW6lHXJbIc+ONN6b9sx999BEAzZo1q/Qx22yzjTueN28eEE/csqjt22+/BeKzCiGwKHKP\nPfbIyfPb7BPAySefnHDen6nKF0VcIiISlJKJuPxRv2PHjpU+7pprrnHHFmmZJUuWuGOLOp555hnX\nNnLkSAA233xz12bRl6XSlkLEZd84/YjV7hOkEmUley5f9+7d3bEiLrFlJhtvvHHCOX9Jhs2Q+CxK\n2myzzRKe48477wSgadOmVb6+zQr06NEDgA8//DDFnheHffbZB4BTTz014VyyyLIqa3q8tb333ntp\n9zObFHGJiEhQNHCJiEhQSmaqsGHDhu7YqmT4LIXdT8VOxeTJk93x+eefD8SnCkvZgw8+mJPnrepG\nutQ8fgKUsSUqL7/8sms7+OCDEx5nSzLatm0LwGGHHebOrWmK0Ngyl1CrldhSgP79+7s2+xu46aab\nurZUpgptyhWgT58+Ceft9oFfgagQFHGJiEhQSibi6tatW0Kbn0bcr18/IEqfrQ5bTPvf//7XtVm1\ndFs8ecMNN7hzfup9TbPXXnsBcMQRRySce//99/PdHSlic+fOBeLp3LaAfeDAgSk9hy2W9+tlml9+\n+cUdX3vttUC03AWgdevWQFQncubMmSn3vRj8/PPPsX8h2nkgXXYNIIq4/ISzESNGAIVfMqCIS0RE\ngqKBS0REghL8VOEGG2wARDcoff56jBkzZmT8WvZ8EydOdG02BTls2DAgvu7E3xKllNkatkMPPdS1\n2QaSfq3Hn376CYDBgwfnsXdS7C655BIgnhjQq1cvILWEAoimCP21mC+99BIQn76fP38+EE1FQvS3\nw5I/QptMRxAnAAAWdUlEQVQqzKbDDz88oe3FF190x+mu48wVRVwiIhKU4COutddeG4jX1cu1119/\nvdJzZ5xxhjtOFgWGqkWLFkBUkxGiDf3sm6pVNq+MVcmwenEiPj8Sv++++6r1HH41988//zytn915\n552r9ZqlxN9Rw6LdYvy8KuISEZGgaOASEZGgBD9VWJVPP/200F0Ihr/CfsGCBQA0adLEtdk6GX9z\nyVQccsgh7viJJ57IpItS4vxkqlwXurVpbl9VtwBqCj8Zxo5TTZDJJ0VcIiISlOAjruOPP77Sc7at\ngayZLSuA1Gu8pcL/tpasqkFNZltI+FtJpBvRSnratGkDxGcCvvrqK6Bmb7Gz7777Vnqufv367njc\nuHFAPBnOkrLss3711Ve7c2PHjs1qP40+JSIiEpTgIy5/W26pPtuQD2DSpElA/B7X9OnTAfjiiy8S\nfrZx48ZAfCmAVYD3N+40jz/+eOYdLgHJ7iFYVDpgwADX5tfVk/T5W8/b+9iPbO09/e677+a3Y1nm\nb6K56667ArDJJpu4tmS7ZpiDDjqo0nN+inwyttmuFV8YP378mjubIUVcIiISFA1cIiISlOCnCiU7\n/G0KevbsWa3n8DfpvO2224D4djM25eDXglPCRnJWEUaqzxKO/Nqilmjgv+8effTR/HYsy2w7GD8p\nYv/99wfiiT/VTWu3qUCAc845J+F8IZYRKOISEZGglGTEZRuq+ZWi86WmVIRP5rvvvnPHRx11FADP\nPvusa+vatWvsHMD999+fp95JTWPJCMkqnr/88svu+Oabb85bn3LBUvsPOOAA1/bee+8B8Ouvvya0\nJUuO6t+/PwBbbLGFa7MkraqSOgpFEZeIiARFA5eIiASlJKcK7cb2hhtumNXn3XrrrQG46KKLKn3M\n5MmTs/qauWIb6a1atQqAX375JSev409L7LXXXgBceumlrk1ThZINtlbrjjvucG1+dQxjiQQ2NQbp\nb39SbBYvXgzAyJEjXZutA7TbJmty1llnAdGazGKniEtERIISfMS1aNGihLY6deoAcNlll7m2adOm\nZfxa//73vwH405/+lHDOth//4YcfMn6dXPG3RrcU4HvuuQeAUaNGZfz8dt0hqqKRLLXe3zZd5KST\nTgKgS5curq1Dhw7AmlO4bSeDPffcE4jX1UvGEjVyXX0+n2yWJ9uzPcVc61URl4iIBEUDl4iIBCX4\nqcJHHnmk0nP+5ojV5ScS2HSEz9ZtWbn/1atXZ/yaueJPcbZt2xaA1q1bA9CgQQN37p///GdKz3fE\nEUcA0XU++uij3Tkrfpxs5f65556bbtelBFlh1wkTJiScsyK4a6qsYmsDkz1+5cqVQLz4cylNEWaD\nFeZdd911E87lKmErGxRxiYhIUIKPuOxbgaWEArRs2RKAbbfd1rWNGTMGgBEjRri2999/v9Ln7dSp\nEwADBw50bbVr/3G5/OoYnTt3Boo7KcN8+eWX7tgqB9j2B34iy+WXXw7Eb4xb5JTsZnlV51asWOGO\nhw8fDsCsWbOq9wuUiFq1agFKUjn44IOB5O8bi5xSra+X7PGWuDF79uxMulnS7POfzc1j80ERl4iI\nBCX4iMsW2FmEBNE3eou8IKpMbhESJNYos7RciLamtijLN3r0aHdciHqI1eVXce7duzcAV1xxBRB9\n+4Uord2/P2WS3bOyGmi2eSREEe6DDz7o2vy6hTWZLfI88cQTE87ZfZlsLN8oRlaxHaB9+/Y5fa29\n994biL/vdtllFwCWLl2a09cOjX2u7f0HqS9eLgRFXCIiEhQNXCIiEpSy6m4ulpUXLyvLyYvbthlX\nXnmla/OnDdPxzjvvuGObZvSnB7O5EWJ5eXni3FwVsnn99tlnH3d8wgknAPGpU6s5OGXKFNdmv/vU\nqVMB2H777d25F198MVtdS1m61w9y9x6sik2XWX04SwsHGDRoEABz5szJd7fycv1s+QVU/R6pKuHH\n3/jRbgvY4/2lFrYkw2fbdnz11VfpdDtlhfwMV0fHjh2B6Dq+8cYb7lyrVq3y3p9Ur58iLhERCUpJ\nRlzGT6xo1KgREF+MaDeH586dm/Cztijyk08+cW1WST1XQvu2VmxCibiKVT6un79RoS2P8DcWNbaM\nwiJQgIkTJwLxDUsrfiY32mgjd1y3bl0gPtvywgsvALBs2bJ0up2y0D7DFSOuu+66y5075ZRT8t4f\nRVwiIlKSNHCJiEhQSnqqMDShTTMUG00VZkbXL3OhfYaHDh0KQL9+/YD4tK0lXeWTpgpFRKQkBV85\nQ0REqsdqvb722mtAYaKs6lDEJSIiQdHAJSIiQVFyRhEJ7cZusVFyQWZ0/TKnz3BmlJwhIiIlqaAR\nl4iISLoUcYmISFA0cImISFA0cImISFA0cImISFA0cImISFA0cImISFA0cImISFA0cImISFA0cImI\nSFA0cImISFA0cImISFA0cImISFA0cImISFA0cImISFA0cImISFA0cImISFA0cImISFA0cImISFA0\ncImISFA0cImISFA0cImISFA0cImISFA0cImISFA0cImISFBqF/LFy8rKygv5+sWmvLy8LJ3H6/rF\npXv9QNfQp+uXOX2GM5Pq9VPEJSIiQdHAJSIiQdHAJSIiQdHAJSIiQdHAJSIiQSloVqGEZ621ou86\nzZo1i53r1auXO37ppZcAeO6551zb559/ntO+iSQzePBgd7zZZpsBcOedd7q2559/Pu99kswo4hIR\nkaBo4BIRkaBoqpBoyuuwww5zbd27dwegY8eOru3333+v9Dn2339/AObMmZP9DhaBNm3aAPCPf/zD\ntdk1Sqas7I91hF9//bVrO/LIIwGYN29eLrooQuvWrd3x+PHjAdhll11c29prrw1A3bp1XdvLL78M\nwK+//pqPLhalvn37AvG/Xza1X4xT/Iq4REQkKGXl5YWrOFLociddunQBYOjQoQC0atUq4TEWOQBU\nda1+/PFHAHbddVfXtmTJkrT6UyzlYtZZZx0A/vWvf7m2zp07A7DuuusmPP6xxx4D4t/MNthgAwCO\nPvpo17Z06VIAttpqK9e2YsWKbHVbJYsyFPL1GzZsGAA9evRwbRWThyqz4447AvD2229n3I9i+Qwn\nc8ABBwBw3nnnuTaLULfccksAvv/+e3du5cqVAHz00Ueuba+99sppH1XySURESlKNucdlc9sXXHCB\naxsyZAhQdSSVqo022giAc845x7X169cv4+cthIcffhiADh06uLZbbrkFgEcffdS1zZ8/H4juDaxe\nvdqds7T5WrVquTa7x+Vfo+uvvz6rfS9WderUcccWcV555ZUAnHjiiWk91+jRo93xwIEDgSiahey8\nn4vZ+uuv747tPutZZ50FRJH+mixevNgd22xJKapfv747Hj58OAAtW7as9PH2d6yytmeffRaA4447\nzrV9+OGHmXYzbYq4REQkKBq4REQkKCWdnOEnVlga99VXX51wvqpr4D+HvwLf9O/fP/Y4P2zu2rUr\nAG+++WZK/S2WG7s//fQTEJ/GGzRoULWey9LoAZ5++mkgSoaB6KZ6NhRTcoFNlVqCwIwZM9y5Fi1a\nZP31jjnmGHc8efLkaj1HMV2/qtx0003uuE+fPmn97KeffgrAmDFjXNt1112XnY5RPJ/h448/HoAz\nzjjDte29996VPn7ZsmVAfMrZlgw0bNgw4fEjR450xxdddBEAG2+8MRBP8EiXkjNERKQklWRyhqV4\n9u7d27X53zwqsihp2rRpru2hhx4C4Jlnnkl4vP+N2SIu07Rp04TjVCOuYpON9OAFCxa44w8++CDj\n5wuFLa1YuHBhpY9ZtWoVkDw5wH/P2A12q7Nn32whiuz8heEzZ84EMvvmW4zsc20zGamyJCyIlnhk\n471dbP7617+644kTJwKpJ+rYz/oLkDfffHMgnpBl/wd+4tYNN9wQazvttNPcuUWLFqX+C6RBEZeI\niARFA5eIiASlZKYK/SQKmyKsanoQoooPl156KQCvvfZajnoXFrt+Va33SNW+++7rjq1CQamxtWrb\nbbeda7vvvvsqffyrr74KROu4bN3cmuy5555AfHr6kEMOAeDPf/6za7NpQ3tfh+jYY48F4NZbb3Vt\ntWv/8efKKrsk49cbtM//v//9b9dWVb3RUFkihk0PQjSFnOz3vfvuu91xVWsIrRLOu+++69qsMpCf\ndLXbbrvFfu6RRx5xx/6tk2xSxCUiIkEJPuJKVhGjqkjLr1buV4OXyL333pu15/IrRvhVNELnV28Y\nN24cEE9Jr+jmm292x5Z+/fHHH6f0Wuuttx4QVWKxKKvU+NfPUt5TrYTxySefAPElHHfddVcWe1d8\nTj75ZCCqpOInYlik5ddLtWoXtslrqqx6PkTVb/xIrmICSOPGjd2xJWrcfvvtab3mmijiEhGRoAQf\ncW299dZAfGFxMlZrz/bokfzo1q1bobuQE/63ymSR1m+//QZE9eHs/QepR1rG3rNVXUs/9f3bb79N\n6/kLzWY+/HtRdo8mVXbP5auvvspex4qcRTPJ7vl99tlnAPztb39zbf7SlHT4/y9WhMGeH6KCBdtv\nvz0Qn1nxZyaySRGXiIgERQOXiIgEJfipQlut7afDG38DNLvZm+0qFva6ydJPk/WpprAp3F69eiWc\n82/2hsamZfxqAub11193x5ZI4dcoTIdfncVPPa7oiSeeAOKp76FcX1tuYUsHUp0enD59ujs+9dRT\nAfjmm29S+lm7lltssUXCOatyYokexcjfyNUS05Kx6eXqTg/6/KlnmxZ/5513XJtNESZL6jrhhBOA\neG3DbFDEJSIiQQk24rK6bbZYNllNrgceeMAdZzPSuuKKK9yxva5FWrNnz3bnktU5rCk23XRTIH5z\n9j//+Q8As2bNKkifssG+cfqLjS0Rw39fVDfSOvTQQ4F4Kneyzf3MNddcA4QTZflSWVDss0jrlFNO\ncW2//PILAAceeCAAZ599dpXPsfvuuwNRHT6fXUOrZwgwduxYIPo/LjRbegHxRecQX8he3d0cklm+\nfLk79v+mGou4krHahtmmiEtERIKigUtERIIS7FSh3WS10N9ntbKuuuqqrL6mrf7u3LlzpY8ZMWKE\nO/ZD7JqgXbt27timuvxklYsvvhgonmmX6thhhx0S2mw6aerUqdV6zmuvvdYd29qcqqYH/bVKIdfX\ntGnRqvjTyrYm6aijjnJtdr38mpjVZXX47F+AJ598EoBXXnkl4+fPRN++fQHo2bNnwjlLJrGqFoWS\nLBntwgsvzMlrKeISEZGgBBtxde/evdJzlgaf7Yinffv2ADRo0CDhnCVizJ07N6uvWUj+lt2HH344\nAKeffrprq3hT3b9Ja6m6ftKMfSO0m/IQZlJBRe+9915aj99www2BaPM+f+M9f5PIyviVOkKrkuH7\n4Ycf1vgYfynAW2+9BcTfl7a9fKnbZZddgORJaOnWHswG/7M+dOhQIPVNK7NBEZeIiAQl2IirqoXH\nNh+cDZMnT3bH/qLQimyBcyrfIouRHz0NHDgQgHPOOce1pfvN1u5t+fezBgwYAMQXy06bNg2IFvT6\nqci2INX/1r3VVlsB8f+XQrOIyd+HyGoH/uUvfwHi92Xatm0LpJ8q/PjjjwPw/PPPV7+zRaSqvaCM\nH4GmEo363/p//PFHIIpwIdyiAHat/N/P7m/aIux8Ouuss9zxNttsEzvn34OdNGlSTl5fEZeIiARF\nA5eIiAQl2KlCC5mzeUPQNuyDqLaWnwSS7LVsO5VkK8pD8Kc//QmIb/RmU1n+lt3z588H4pVBJkyY\nEHuuL774wh2feeaZQHzq1NLh/XRju772r19DbpNNNgHilRLuv/9+oHBThckSMez3mTNnjmuzrR7s\npno22BSMVYuQiE3V//zzz67NElf8qemqphttGtFqFkJ849liY5uT5ipBp1GjRkBUpQii6jD+1HfF\nv4u//vqrO/78889z0jdFXCIiEpRgI65sspv//rbflvqejL+J2p133pm7juXQfvvtB0SLZ3fccUd3\nbuLEiUAUIUFUc9DO+T799FMgvqV8soWxtmTAEiwAOnXqBEQRn78hqEVrQ4YMcW033njjGn6z3LIo\n01/waotCK96krsx3330HRBGan5Bi18O/+W0sHVwSdenSBYgnX6T6/2EsocivE5mriCEbFi1alPXn\n9GdDLHEqWV3HqvhJSrmiiEtERIJSkhGXLXR98MEHq3zcqFGjgGjvqKqiLJ8fdfh7foXE7ilZpLV4\n8WJ3ziIov61evXoAbLDBBq5tyZIlQLT1eqrlh/yt621bcKv87S9wtohk3rx5KT1vPqxevRqIV4K3\nrcptfymIrpPdU7HK+BBF6TNnzkx4/ksuuSShza5zqNF9Ze644w6g6v3G1sQirG233bbaz7Fy5UoA\nbr31ViD6u1BMku33ZwvR7T6q7cEFUSk8//6TLSHyWWGBjh07Jjx/Kv3xf8Z2Krj88stTeo5MKOIS\nEZGgaOASEZGglOWzvlTCi5eVVfvF7Wb+ySefnHDOkgCmTJni2mzDyZ133tm1JQu/K/JDYpvG8at5\nZ1N5eXlay/ozuX6W5msbPq7J+++/D8STI2xqpVike/0gs2tYkX8t69SpA0QVR2y6Lxm/qv4TTzwB\nRFOzEFUfSFYZPJvyff2aNGkCwGOPPQZAq1atqvtUafPr+1lih1/xobpy9Rm2Kepkf6/tnL8cxaaq\n/cdXteOATbmmOh74STD23rbNPP1lNOlK9fop4hIRkaAEG3HZDV1L2fQXyaXx+kDybxmvv/46AHff\nfbdrGz58OJC7/aTyGXGdd955QPQ7+QuLbfGsn1Bwzz33AFH9t2JU6Iiruvz04a5duyact4jsueee\ny2k/CnX9LPLyf/cbbrgBiJZhpGrVqlXu2F9IbMaNGwfE39vZTHnP1WfYZjwskSyF57X+ZPx4f0Gx\nXVOb1YIoaSiTSMso4hIRkZKkgUtERIIS7FShsXUIfiJGGq8PwLJly4D49tzHH388kN91WvmcKrTk\nAZum8auB2LqW0IQ2VWh1Gf1p2ubNmwPwwQcfuDZbX5jrKg7FdP0OPfRQABo3buzaRo8eDcQ3iK24\n7m3FihXu2J/mz5dcfYZtfeNll13m2uxvk1Ve8etiduvWDYgn+dSvXx+Ikjkg+twnS1Sz6/3mm2+6\nthkzZqTS3WrTVKGIiJSk4CMuq0xgERJEld1TeH0g2giw0JUJ8hlxlaJiihhS0a9fPwCGDRuWcM6v\n4mKV+XMttOtXjIrtM7z99tu7Y6slaslXEFUvKRaKuEREpCQFH3GVkmL7thaaUCIGu6/41FNPAdCi\nRQt37vHHHwei+o8QvyeRS6Fcv2Kmz3BmFHGJiEhJ0sAlIiJBKcltTUSKmW2k6U8RGtvKJV/TgyIh\nUsQlIiJBUXJGEdGN3cwouSAzun6Z02c4M0rOEBGRkqSBS0REgqKBS0REgqKBS0REglLQ5AwREZF0\nKeISEZGgaOASEZGgaOASEZGgaOASEZGgaOASEZGgaOASEZGgaOASEZGgaOASEZGgaOASEZGgaOAS\nEZGgaOASEZGgaOASEZGgaOASEZGgaOASEZGgaOASEZGgaOASEZGgaOASEZGgaOASEZGgaOASEZGg\naOASEZGgaOASEZGgaOASEZGgaOASEZGgaOASEZGgaOASEZGgaOASEZGgaOASEZGgaOASEZGgaOAS\nEZGg/B/8VHFCytRcpgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb8f595b590>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Lets look at train data\n",
    "plt.figure(figsize=(2. * 2.5, 2.26 * 2))\n",
    "plt.title(\"Face completion with multi-output estimators\")\n",
    "           \n",
    "for i in range(20):\n",
    "    img = train_img[i].reshape((28,28))\n",
    "    sub = plt.subplot(4,5,i+1)\n",
    "    sub.axis(\"off\")\n",
    "    sub.imshow(img, cmap=plt.cm.gray, interpolation=\"nearest\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code challenge: spot the bug in Logistic Regression code!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "Average loss epoch 0: 1.2892788147\n",
      "Average loss epoch 1: 0.731931714745\n",
      "Average loss epoch 2: 0.600197836653\n",
      "Average loss epoch 3: 0.536738563251\n",
      "Average loss epoch 4: 0.497671618606\n",
      "Average loss epoch 5: 0.471199354439\n",
      "Average loss epoch 6: 0.45149856382\n",
      "Average loss epoch 7: 0.43610518351\n",
      "Average loss epoch 8: 0.423453294592\n",
      "Average loss epoch 9: 0.41329353631\n",
      "Average loss epoch 10: 0.404241379116\n",
      "Average loss epoch 11: 0.396733892582\n",
      "Average loss epoch 12: 0.390273983141\n",
      "Average loss epoch 13: 0.384668713579\n",
      "Average loss epoch 14: 0.379304208018\n",
      "Average loss epoch 15: 0.374681006014\n",
      "Average loss epoch 16: 0.370363724954\n",
      "Average loss epoch 17: 0.366507528441\n",
      "Average loss epoch 18: 0.363026009434\n",
      "Average loss epoch 19: 0.359583337824\n",
      "Average loss epoch 20: 0.356821901836\n",
      "Average loss epoch 21: 0.353949410272\n",
      "Average loss epoch 22: 0.351104522988\n",
      "Average loss epoch 23: 0.348559673919\n",
      "Average loss epoch 24: 0.34637454819\n",
      "Average loss epoch 25: 0.344262852362\n",
      "Average loss epoch 26: 0.342399885604\n",
      "Average loss epoch 27: 0.340312661165\n",
      "Average loss epoch 28: 0.338242351384\n",
      "Average loss epoch 29: 0.336773394948\n",
      "Total time: 26.2543110847 seconds\n",
      "Optimization Finished!\n",
      "Accuracy 0.9121\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "# Define paramaters for the model\n",
    "learning_rate = 0.01\n",
    "batch_size = 128\n",
    "n_epochs = 30\n",
    "\n",
    "# Step 1: Read in data\n",
    "mnist = input_data.read_data_sets('MNIST_data/', one_hot=True) \n",
    "\n",
    "# Step 2: create placeholders for features and labels\n",
    "# X = tf.placeholder(tf.float32, [batch_size, 784], name='X_placeholder') \n",
    "# y = tf.placeholder(tf.float32, [batch_size, 10], name='Y_placeholder')\n",
    "X = tf.placeholder(tf.float32, [None, 784], name='X_placeholder') \n",
    "y = tf.placeholder(tf.float32, [None, 10], name='Y_placeholder')\n",
    "\n",
    "\n",
    "\n",
    "# Step 3: create weights and bias\n",
    "# w is initialized to random variables with mean of 0, stddev of 0.01\n",
    "# b is initialized to 0\n",
    "# shape of w depends on the dimension of X and Y so that Y = tf.matmul(X, w)\n",
    "# shape of b depends on Y\n",
    "with tf.variable_scope('my_model'):\n",
    "    w = tf.Variable(tf.random_normal(shape=[784, 10], stddev=0.01), name='weights')\n",
    "    b = tf.Variable(tf.zeros([1, 10]), name=\"bias\")\n",
    "\n",
    "with tf.name_scope('my_ops'):\n",
    "    # Step 4: build model\n",
    "    # the model that returns the logits.\n",
    "    logits = tf.matmul(X, w) + b \n",
    "\n",
    "with tf.name_scope('train_op'):\n",
    "    # Step 5: define loss function\n",
    "    # use cross entropy of softmax of logits as the loss function\n",
    "    entropy = tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=y, name='loss')\n",
    "    loss = tf.reduce_mean(entropy) # computes the mean over all the examples in the batch\n",
    "\n",
    "    # Step 6: define training op\n",
    "    # using gradient descent with learning rate of 0.01 to minimize loss\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss)\n",
    "\n",
    "gpu_opts = tf.GPUOptions(per_process_gpu_memory_fraction=0.5)\n",
    "with tf.Session(config=tf.ConfigProto(gpu_options=gpu_opts)) as sess:\n",
    "    \n",
    "    \n",
    "    start_time = time.time()\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    n_batches = int(mnist.train.num_examples/batch_size)\n",
    "    for i in range(n_epochs): # train the model n_epochs times\n",
    "        total_loss = 0\n",
    "\n",
    "        for _ in range(n_batches):\n",
    "            X_batch, Y_batch = mnist.train.next_batch(batch_size)\n",
    "            _, loss_batch = sess.run([optimizer, loss], feed_dict={X: X_batch, y:Y_batch}) \n",
    "            total_loss += loss_batch\n",
    "        print 'Average loss epoch {0}: {1}'.format(i, total_loss/n_batches)\n",
    "\n",
    "    print 'Total time: {0} seconds'.format(time.time() - start_time)\n",
    "\n",
    "    print('Optimization Finished!') # should be around 0.35 after 25 epochs\n",
    "\n",
    "    # We can test the model two ways: for small dataset all at once for biger we need do it by batch\n",
    "    #1. All at once\n",
    "    with tf.name_scope('test_op'):\n",
    "#         correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(y, 1))\n",
    "#         accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "#     print sess.run(accuracy, feed_dict={X: mnist.test.images, y: mnist.test.labels})\n",
    "\n",
    "    #2. by batch\n",
    "        n_batches = int(mnist.test.num_examples/batch_size)\n",
    "        total_correct_preds = 0\n",
    "        for i in range(n_batches):\n",
    "            X_batch, Y_batch = mnist.test.next_batch(batch_size)\n",
    "            _, loss_batch, logits_batch = sess.run([optimizer, loss, logits], feed_dict={X: X_batch, y:Y_batch}) \n",
    "            preds = tf.nn.softmax(logits_batch)\n",
    "            correct_preds = tf.equal(tf.argmax(preds, 1), tf.argmax(Y_batch, 1))\n",
    "            accuracy = tf.reduce_sum(tf.cast(correct_preds, tf.float32)) # need numpy.\n",
    "            total_correct_preds += sess.run(accuracy)\n",
    "\n",
    "        print 'Accuracy {0}'.format(total_correct_preds/mnist.test.num_examples)\n",
    "    writer = tf.summary.FileWriter('./MNIST_data/test/graph', sess.graph)\n",
    "    writer.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Second try and logistic regression evolved to neural network\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "INFO: global variables\n",
      "my_model/W0 (784, 128)\n",
      "my_model/b0 (1, 128)\n",
      "my_model/W1 (128, 10)\n",
      "my_model/b1 (1, 10)\n",
      "Average loss epoch 0: 2.22554425815\n",
      "Average loss epoch 1: 1.54468943411\n",
      "Average loss epoch 2: 0.85266346045\n",
      "Average loss epoch 3: 0.616764632347\n",
      "Average loss epoch 4: 0.514196301743\n",
      "Average loss epoch 5: 0.456699790724\n",
      "Average loss epoch 6: 0.419851628564\n",
      "Average loss epoch 7: 0.394577542246\n",
      "Average loss epoch 8: 0.37542702737\n",
      "Average loss epoch 9: 0.360566297924\n",
      "Average loss epoch 10: 0.348560312168\n",
      "Average loss epoch 11: 0.338425017216\n",
      "Average loss epoch 12: 0.329327114743\n",
      "Average loss epoch 13: 0.322021806921\n",
      "Average loss epoch 14: 0.314596724955\n",
      "Average loss epoch 15: 0.308453202942\n",
      "Average loss epoch 16: 0.302141304338\n",
      "Average loss epoch 17: 0.296854825321\n",
      "Average loss epoch 18: 0.291647452852\n",
      "Average loss epoch 19: 0.286763318665\n",
      "Average loss epoch 20: 0.281887119501\n",
      "Average loss epoch 21: 0.277565700087\n",
      "Average loss epoch 22: 0.273072252688\n",
      "Average loss epoch 23: 0.268918945204\n",
      "Average loss epoch 24: 0.264596742489\n",
      "Average loss epoch 25: 0.260856094494\n",
      "Average loss epoch 26: 0.257020100899\n",
      "Average loss epoch 27: 0.253436894215\n",
      "Average loss epoch 28: 0.249826371201\n",
      "Average loss epoch 29: 0.246370851803\n",
      "Total time: 15.7192389965 seconds\n",
      "Optimization Finished!\n",
      "Accuracy 0.931400179863\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "# Define paramaters for the model\n",
    "learning_rate = 0.01\n",
    "batch_size = 128\n",
    "n_epochs = 30\n",
    "\n",
    "# Step 1: Read in data\n",
    "mnist = input_data.read_data_sets('MNIST_data/', one_hot=True) \n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, 784], name='X_placeholder') \n",
    "y = tf.placeholder(tf.float32, [None, 10], name='Y_placeholder')\n",
    "\n",
    "# Step 2: Define model\n",
    "# Variable and name scopes, helps better structure our models\n",
    "with tf.variable_scope('my_model'):\n",
    "    w = tf.Variable(tf.random_normal(shape=[784, 128], stddev=0.01), name='W0')\n",
    "    b = tf.Variable(tf.zeros([1, 128]), name=\"b0\")\n",
    "    with tf.name_scope('my_ops'):\n",
    "        pred =  tf.nn.relu(tf.matmul(X, w) + b)\n",
    "\n",
    "    w1 = tf.Variable(tf.random_normal(shape=[128, 10], stddev=0.01), name='W1')\n",
    "    b1 = tf.Variable(tf.zeros([1, 10]), name=\"b1\")\n",
    "    with tf.name_scope('my_ops'):\n",
    "        logits =  tf.matmul(pred, w1) + b1\n",
    "\n",
    "    print \"INFO: global variables\"\n",
    "    for i in tf.global_variables():\n",
    "        print i.op.name, i.get_shape()\n",
    "\n",
    "# Step 3: Define training ops\n",
    "with tf.name_scope('train_op'):\n",
    "    entropy = tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=y, name='loss')\n",
    "    loss = tf.reduce_mean(entropy) # computes the mean over all the examples in the batch\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss)\n",
    "\n",
    "gpu_opts = tf.GPUOptions(per_process_gpu_memory_fraction=0.5)\n",
    "with tf.Session(config=tf.ConfigProto(gpu_options=gpu_opts)) as sess:\n",
    "    \n",
    "    start_time = time.time()\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    n_batches = int(mnist.train.num_examples/batch_size)\n",
    "    for i in range(n_epochs): # train the model n_epochs times\n",
    "        total_loss = 0\n",
    "\n",
    "        for _ in range(n_batches):\n",
    "            X_batch, Y_batch = mnist.train.next_batch(batch_size)\n",
    "            _, loss_batch = sess.run([optimizer, loss], feed_dict={X: X_batch, y:Y_batch}) \n",
    "            total_loss += loss_batch\n",
    "        print 'Average loss epoch {0}: {1}'.format(i, total_loss/n_batches)\n",
    "\n",
    "    print 'Total time: {0} seconds'.format(time.time() - start_time)\n",
    "    print('Optimization Finished!') # should be around 0.35 after 25 epochs\n",
    "\n",
    "    # We can test the model two ways: for small dataset all at once for biger we need do it by batch\n",
    "    \n",
    "    with tf.name_scope('test_op'):\n",
    "        correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(y, 1))\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "        acc =  sess.run(accuracy, feed_dict={X: mnist.test.images, y: mnist.test.labels})\n",
    "\n",
    "    print 'Accuracy {0}'.format(acc)\n",
    "    writer = tf.summary.FileWriter('./MNIST_data/test/graph, sess.graph)\n",
    "    writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving model\n",
    "It's all good, but how we could, save our progress? Use **tf.train.Saver** that saves graph’s variables in binary files. Saver create checkpoint files that only save variables, not graph. Checkpoints map variable names to tensors on load.\n",
    "\n",
    "Let's try to train model, save it and reuse it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "Average loss epoch 0: 2.24213921996\n",
      "Global step:  429\n",
      "Average loss epoch 1: 1.62041481614\n",
      "Global step:  858\n",
      "Average loss epoch 2: 0.880781664576\n",
      "Global step:  1287\n",
      "Average loss epoch 3: 0.622332877212\n",
      "Global step:  1716\n",
      "Average loss epoch 4: 0.513954840201\n",
      "Global step:  2145\n",
      "Total time: 5.74288702011 seconds\n",
      "Optimization Finished!\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "n_epochs = 5\n",
    "\n",
    "# Step 1: Read in data\n",
    "mnist = input_data.read_data_sets('MNIST_data/', one_hot=True) \n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, 784], name='X_placeholder') \n",
    "y = tf.placeholder(tf.float32, [None, 10], name='Y_placeholder')\n",
    "\n",
    "# Step 4: Define training ops\n",
    "with tf.variable_scope('my_model'):\n",
    "    w = tf.Variable(tf.random_normal(shape=[784, 128], stddev=0.01), name='W0')\n",
    "    b = tf.Variable(tf.zeros([1, 128]), name=\"b0\")\n",
    "    with tf.name_scope('my_ops'):\n",
    "        pred =  tf.nn.relu(tf.matmul(X, w) + b)\n",
    "\n",
    "    w1 = tf.Variable(tf.random_normal(shape=[128, 10], stddev=0.01), name='W1')\n",
    "    b1 = tf.Variable(tf.zeros([1, 10]), name=\"b1\")\n",
    "    with tf.name_scope('my_ops'):\n",
    "        logits =  tf.matmul(pred, w1) + b1\n",
    "\n",
    "#We need to know whick iteration we are executing\n",
    "global_step = tf.Variable(0, dtype=tf.int32, trainable=False, name='global_step')\n",
    "\n",
    "# Step 3: Define training ops\n",
    "with tf.name_scope('train_op'):\n",
    "    entropy = tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=y, name='loss')\n",
    "    loss = tf.reduce_mean(entropy) # computes the mean over all the examples in the batch\n",
    "    #We pass global_step to optimizer\n",
    "    optimizer = tf.train.GradientDescentOptimizer(0.01).minimize(loss, global_step=global_step)\n",
    "\n",
    "# Step 4: We create saver object\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "# Step 5: We create dir where to store checkpoint files\n",
    "save_dir = './MNIST_data/test/nn/'\n",
    "if not exists(save_dir):\n",
    "    os.mkdir(save_dir)\n",
    "    \n",
    "gpu_opts = tf.GPUOptions(per_process_gpu_memory_fraction=0.5)\n",
    "with tf.Session(config=tf.ConfigProto(gpu_options=gpu_opts)) as sess:\n",
    "    \n",
    "    start_time = time.time()\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    n_batches = int(mnist.train.num_examples/batch_size)\n",
    "    for i in range(n_epochs): # train the model n_epochs times\n",
    "        total_loss = 0\n",
    "\n",
    "        for _ in range(n_batches):\n",
    "            X_batch, Y_batch = mnist.train.next_batch(batch_size)\n",
    "            _, loss_batch = sess.run([optimizer, loss], feed_dict={X: X_batch, y:Y_batch}) \n",
    "            total_loss += loss_batch\n",
    "        print 'Average loss epoch {0}: {1}'.format(i, total_loss/n_batches)\n",
    "        print 'Global step: ', global_step.eval()\n",
    "    \n",
    "        #We save model variables to checkpoint_files after every epoch\n",
    "        saver.save(sess, save_dir+'model', global_step=global_step)\n",
    "    \n",
    "    print 'Total time: {0} seconds'.format(time.time() - start_time)\n",
    "    print('Optimization Finished!') # should be around 0.35 after 25 epochs\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's load saved model\n",
    "As you look to ./MNIST_data/test/nn you will find bunch of files. One we are interested is **checkpoint** look at it.\n",
    "It contains list of our saved models. So lets try to load model from checkpoint.\n",
    "\n",
    "There is two ways to load chechpoints\n",
    "1. Define model, and do restore operatoin\n",
    "2. Load model from checkpoint files\n",
    "\n",
    "We gona use option number 1. So lets do it\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "INFO: all chekpoint list:  [u'./MNIST_data/test/nn/model-429', u'./MNIST_data/test/nn/model-858', u'./MNIST_data/test/nn/model-1287', u'./MNIST_data/test/nn/model-1716', u'./MNIST_data/test/nn/model-2145']\n",
      "INFO: last checkpoint:  ./MNIST_data/test/nn/model-2145\n",
      "INFO: restoring model:  ./MNIST_data/test/nn/model-2145\n",
      "Accuracy 0.882700026035\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "n_epochs = 5\n",
    "\n",
    "# Step 1: Read in data\n",
    "mnist = input_data.read_data_sets('MNIST_data/', one_hot=True) \n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, 784], name='X_placeholder') \n",
    "y = tf.placeholder(tf.float32, [None, 10], name='Y_placeholder')\n",
    "\n",
    "# Step 2: Define model\n",
    "with tf.variable_scope('my_model'):\n",
    "    w = tf.Variable(tf.random_normal(shape=[784, 128], stddev=0.01), name='W0')\n",
    "    b = tf.Variable(tf.zeros([1, 128]), name=\"b0\")\n",
    "    with tf.name_scope('my_ops'):\n",
    "        pred =  tf.nn.relu(tf.matmul(X, w) + b)\n",
    "\n",
    "    w1 = tf.Variable(tf.random_normal(shape=[128, 10], stddev=0.01), name='W1')\n",
    "    b1 = tf.Variable(tf.zeros([1, 10]), name=\"b1\")\n",
    "    with tf.name_scope('my_ops'):\n",
    "        logits =  tf.matmul(pred, w1) + b1\n",
    "\n",
    "# Step 3: Define test ops\n",
    "with tf.name_scope('test_op'):\n",
    "    correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(y, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "        \n",
    "# Step 4: Define saver and load last checkpoint, we specify checkpoint dir\n",
    "saver = tf.train.Saver()  \n",
    "ckpt = tf.train.get_checkpoint_state('./MNIST_data/test/nn')\n",
    "\n",
    "print \"INFO: all chekpoint list: \",ckpt.all_model_checkpoint_paths\n",
    "print \"INFO: last checkpoint: \", ckpt.model_checkpoint_path\n",
    "gpu_opts = tf.GPUOptions(per_process_gpu_memory_fraction=0.5)\n",
    "with tf.Session(config=tf.ConfigProto(gpu_options=gpu_opts)) as sess:\n",
    "#Step 5: if you wana be convinced that restore operation do work uncoment code below\n",
    "    \"\"\"\n",
    "    # We initialize variables and check they values\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for i in tf.global_variables():\n",
    "        print \"Before: var: {}, shape: {}, mean: {}\".format(i.op.name, i.get_shape(), tf.reduce_mean(i).eval())\n",
    "    \n",
    "    #We do restore and check again\n",
    "    saver.restore(sess, ckpt.model_checkpoint_path)\n",
    "    for i in tf.global_variables():\n",
    "        print \"After: var: {}, shape: {}, mean: {}\".format(i.op.name, i.get_shape(), tf.reduce_mean(i).eval())\n",
    "    \"\"\" \n",
    "    \n",
    "    print \"INFO: restoring model: \", ckpt.model_checkpoint_path\n",
    "    saver.restore(sess, ckpt.model_checkpoint_path)\n",
    "    acc =  sess.run(accuracy, feed_dict={X: mnist.test.images, y: mnist.test.labels})\n",
    "    print 'Accuracy {0}'.format(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# So you now know kung fu :D\n",
    "\n",
    "lets talk about **Data Readers** - Ops that return different values every time you call them(Think Python’s generator). You now that using feed you can inject data to graph. There is another way. For example you have directory with images and want that tensorflow would load them. No need of some pesky numpy ;D.\n",
    "```python\n",
    "tf.TextLineReader\n",
    "Outputs the lines of a file delimited by newlines E.g. text files, CSV files\n",
    "\n",
    "tf.FixedLengthRecordReader\n",
    "Outputs the entire file when all files have same fixed lengths\n",
    "E.g. each MNIST file has 28 x 28 pixels, CIFAR-10 32 x 32 x 3\n",
    "\n",
    "tf.WholeFileReader\n",
    "Outputs the entire file content\n",
    "\n",
    "tf.TFRecordReader\n",
    "Reads samples from TensorFlow’s own binary format (TFRecord)\n",
    "\n",
    "tf.ReaderBase\n",
    "To allow you to create your own readers\n",
    "```\n",
    "\n",
    "Let me present sample code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Blueprint of Data Readers usage\n",
    "\n",
    "```python\n",
    "img_shape = [128, 128, 3]\n",
    "\n",
    "img = tf.convert_to_tensor(files, dtype=tf.string) #files - list of files in some dir\n",
    "lab = tf.convert_to_tensor(labels, dtype=tf.int32) #labels list of labels\n",
    "\n",
    "#Step 1: Contruct queue, that will produce (img_file, label) pairs\n",
    "filename_queue = tf.train.slice_input_producer([img, lab], num_epochs=num_epochs, seed=random_state, capacity=500, shuffle=False)\n",
    "\n",
    "#Step 2: Construc ops to process single (image, label) pair\n",
    "image = tf.read_file(filename_queue[0])\n",
    "decoded_image = tf.image.decode_jpeg(image, channels=3)\n",
    "decoded_image.set_shape(img_shape)\n",
    "image = tf.to_float(decoded_image)\n",
    "label = tf.cast(filename_queue[1], tf.int32)\n",
    "\n",
    "#Step 3: Construc queue that will suply our model with batch'es of data\n",
    "images_batch, label_batch = tf.train.batch([image, label],\n",
    "                                     batch_size=batch_size,\n",
    "                                     capacity=capacity, num_threads=num_threads)\n",
    "\n",
    "#Step 4: Define model, and pass images to it, remember, that in previos model we used plaseholder as imput to model\n",
    "logits = my_model(images_batch)\n",
    "\n",
    "gpu_opts = tf.GPUOptions(per_process_gpu_memory_fraction=0.05)\n",
    "with tf.Session(config=tf.ConfigProto(gpu_options=gpu_opts)) as sess:\n",
    "\n",
    "#Step 5: Create Coordinator, and run you queues\n",
    "    coord = tf.train.Coordinator()\n",
    "    tf.train.start_queue_runners(sess=sess, coord=coord)\n",
    "    \n",
    "    try:\n",
    "        while not coord.should_stop():\n",
    "#Step 6: Run training ops\n",
    "            pred = sess.run(logits)\n",
    "        except tf.errors.OutOfRangeError:\n",
    "            print('Done training -- epoch limit reached')\n",
    "        finally:\n",
    "            coord.request_stop()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
